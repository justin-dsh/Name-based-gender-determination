{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于名字的性别判断\n",
    "## 概述\n",
    "性别是人类差异最大的特征之一，不同的性别拥有不同的特征，譬如购物、电视剧、书籍等方面男生和女生的爱好有很大的不同。因此，知道了用户的性别就可以更加准确的判断用户的潜在行为和需求。由此可知，性别识别的重要性和价值性不言而喻，每个机器学习模型的构建，基本都会需要准确识别用户的性别。\n",
    "\n",
    "　　目前业内预测用户性别的方法有很多，大多数都是基于用户的行为数据、兴趣等方面进行性别判定，识别的准确性也参差不齐。但是，很多的时候我们拿不到用户的行为数据，这个时候用用户的行为数据、兴趣数据建立机器学习模型就显得力不从心了。同时，从用户的行为数据着手建立模型去预测用户的性别效果也并不会见得有多好，因为影响模型准确性的主要原因是这些用户的行为在性别上区分度有多大，如果区分度不明显，那模型和算法的准确性将会遇到明显的瓶颈。同时，基于用户行为的性别识别涉及的数据面非常广、数据依赖链条很长、数据计算复杂度很高，识别效能反而成为了痛点！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理\n",
    "贝叶斯公式: P(Y|X) = P(X|Y) * P(Y) / P(X)\n",
    "\n",
    "当X条件独立时, P(X|Y) = P(X1|Y) * P(X2|Y) * ...\n",
    "\n",
    "应用到猜名字上\n",
    "\n",
    "P(gender=男|name=本山) \n",
    "= P(name=本山|gender=男) * P(gender=男) / P(name=本山)\n",
    "= P(name has 本|gender=男) * P(name has 山|gender=男) * P(gender=男) / P(name=本山)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长名字的字符数:  3\n",
      "1306\n",
      "('male', 0.5591018119262235)\n",
      "('male', 0.9800590316057012)\n",
      "('female', 0.9968617145628665)\n",
      "('male', 0.8495845552297164)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ngender\n",
    "name_dataset = 'name.csv'\n",
    "tf.reset_default_graph() \n",
    "train_x = []\n",
    "train_y = []\n",
    "with open(name_dataset, 'rt') as f:\n",
    "    first_line = True\n",
    "    for line in f:\n",
    "        if first_line is True:\n",
    "            first_line = False\n",
    "            continue\n",
    "       # uline = str(line,encoding=\"utf-8\")\n",
    "        sample = line.strip().split(',')\n",
    "        if len(sample) == 2:\n",
    "            train_x.append(sample[0])\n",
    "            if sample[1] == '男':\n",
    "                train_y.append([0, 1])  # 男\n",
    "            else:\n",
    "                train_y.append([1, 0])  # 女\n",
    " \n",
    "max_name_length = max([len(name) for name in train_x])\n",
    "print(\"最长名字的字符数: \", max_name_length)\n",
    "max_name_length = 8\n",
    " \n",
    "# 数据已shuffle\n",
    "#shuffle_indices = np.random.permutation(np.arange(len(train_y)))\n",
    "#train_x = train_x[shuffle_indices]\n",
    "#train_y = train_y[shuffle_indices]\n",
    " \n",
    "# 词汇表（参看聊天机器人练习）\n",
    "counter = 0\n",
    "vocabulary = {}\n",
    "for name in train_x:\n",
    "    counter += 1\n",
    "    tokens = [word for word in name]\n",
    "    for word in tokens:\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word] += 1\n",
    "        else:\n",
    "            vocabulary[word] = 1\n",
    " \n",
    "vocabulary_list = [' '] + sorted(vocabulary, key=vocabulary.get, reverse=True)\n",
    "print(len(vocabulary_list))\n",
    " \n",
    "# 字符串转为向量形式\n",
    "vocab = dict([(x, y) for (y, x) in enumerate(vocabulary_list)])\n",
    "train_x_vec = []\n",
    "for name in train_x:\n",
    "    name_vec = []\n",
    "    for word in name:\n",
    "        name_vec.append(vocab.get(word))\n",
    "    while len(name_vec) < max_name_length:\n",
    "        name_vec.append(0)\n",
    "    train_x_vec.append(name_vec)\n",
    " \n",
    "#######################################################\n",
    " \n",
    "input_size = max_name_length\n",
    "num_classes = 2\n",
    " \n",
    "batch_size = 64\n",
    "num_batch = len(train_x_vec) // batch_size\n",
    " \n",
    "X = tf.placeholder(tf.int32, [None, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    " \n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    " \n",
    "def neural_network(vocabulary_size, embedding_size=128, num_filters=128):\n",
    "    # embedding layer\n",
    "    with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "        W = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        embedded_chars = tf.nn.embedding_lookup(W, X)\n",
    "        embedded_chars_expanded = tf.expand_dims(embedded_chars, -1)\n",
    "    # convolution + maxpool layer\n",
    "    filter_sizes = [3,4,5]\n",
    "    pooled_outputs = []\n",
    "    for i, filter_size in enumerate(filter_sizes):\n",
    "        with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "            filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1))\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters]))\n",
    "            conv = tf.nn.conv2d(embedded_chars_expanded, W, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b))\n",
    "            pooled = tf.nn.max_pool(h, ksize=[1, input_size - filter_size + 1, 1, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "            pooled_outputs.append(pooled)\n",
    " \n",
    "    num_filters_total = num_filters * len(filter_sizes)\n",
    "    h_pool = tf.concat(pooled_outputs, 3)\n",
    "    h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "    # dropout\n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        h_drop = tf.nn.dropout(h_pool_flat, dropout_keep_prob)\n",
    "    # output\n",
    "    with tf.name_scope(\"output\"):\n",
    "        W = tf.get_variable(\"W\", shape=[num_filters_total, num_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "        output = tf.nn.xw_plus_b(h_drop, W, b)\n",
    "\n",
    "    return output\n",
    "# 训练\n",
    "def train_neural_network():\n",
    "    output = neural_network(len(vocabulary_list))\n",
    "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=output, lables=Y))\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars)\n",
    " \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    " \n",
    "        for e in range(201):\n",
    "            for i in range(num_batch):\n",
    "                batch_x = train_x_vec[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "                _, loss_ = sess.run([train_op, loss], feed_dict={X:batch_x, Y:batch_y, dropout_keep_prob:0.5})\n",
    "                print(e, i, loss_)\n",
    "            # 保存模型\n",
    "            if e % 50 == 0:\n",
    "                saver.save(sess, \"name2sex.model\", global_step=e)\n",
    " \n",
    "##\n",
    "##train_neural_network()\n",
    " \n",
    "# 使用训练的模型\n",
    "def detect_sex(name_list):\n",
    "    x = []\n",
    "    for name in name_list:\n",
    "        name_vec = []\n",
    "        for word in name:\n",
    "            name_vec.append(vocab.get(word))\n",
    "        while len(name_vec) < max_name_length:\n",
    "            name_vec.append(0)\n",
    "        x.append(name_vec)\n",
    " \n",
    "    output = neural_network(len(vocabulary_list))\n",
    " \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        # 恢复前一次训练\n",
    "        ckpt = tf.train.get_checkpoint_state('.')\n",
    "        if ckpt != None:\n",
    "            print(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        #else:\n",
    "            #print(\"没找到模型\")\n",
    " \n",
    "        predictions = tf.argmax(output, 1)\n",
    "        res = sess.run(predictions, {X:x, dropout_keep_prob:1.0})\n",
    " \n",
    "        i = 0\n",
    "        for name in name_list:\n",
    "            print(name, '女' if res[i] == 0 else '男')\n",
    "            i += 1\n",
    "gue = [\"白富美\",\"高帅富\",\"王婷婷\",\"田野\"]\n",
    "for x in gue:\n",
    "    print(ngender.guess(x))\n",
    "#detect_sex([\"白富美\", \"高帅富\", \"王婷婷\", \"田野\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
